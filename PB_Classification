// load study area and training samples
var dissolved = ee.FeatureCollection("users/Henning/Biodiversity/sichifulo_zam_Dissolve_Chooma_Nyawa");
var sample_sichifulo_23 = ee.FeatureCollection("users/Henning/Biodiversity/sample23corrected");
var sample_sichifulo_20 = ee.FeatureCollection("users/Henning/Biodiversity/sample20corrected");

// Print the training samples to the console to inspect the properties
print('sample_sichifulo_23:', sample_sichifulo_23);
print('sample_sichifulo_20:', sample_sichifulo_20);

//visualize study area and training samples
Map.addLayer(dissolved, {color: 'green'}, 'dissolved');
Map.addLayer(sample_sichifulo_23, {color: 'yellow'}, 'sample_sichifulo_23');
Map.addLayer(sample_sichifulo_20, {color: 'orange'}, 'sample_sichifulo_20');

// Center the map on the study area
Map.centerObject(dissolved, 11);


////////////////////////////////////////////////////////
////////////cloud masking/////////////////////////////7
////////////////////////////////////////////////////////
// Function to remove cloud and snow pixels
function maskS2clouds(image) {
  var cloudProb = image.select('MSK_CLDPRB');
  var snowProb = image.select('MSK_SNWPRB');
  var cloud = cloudProb.lt(5);
  var snow = snowProb.lt(5);
  var scl = image.select('SCL'); 
  var shadow = scl.eq(3); // 3 = cloud shadow
  var cirrus = scl.eq(10); // 10 = cirrus
  // Cloud probability less than 5% or cloud shadow classification
  var mask = (cloud.and(snow)).and(cirrus.neq(1)).and(shadow.neq(1));
 return image.updateMask(mask);
}

/////////////////////////////////////////////////7
//////////Indices calculation////////////////////
//////////////////////////////////////////////////

// Indices: 
// NDVI = (NIR-RED) / (NIR+RED)
// NDWI = (GREEN-NIR) / (GREEN+NIR)
// NDII = (NIR â€“ SWIR1) / (NIR + SWIR1)
// MSI = SWIR1 / NIR
// EVI

function calcNDVI(img){
  return img.addBands(img.normalizedDifference(['NIR','R']).rename('NDVI').float());
}
 
 function calcNDWI(img){
  return img.addBands(img.normalizedDifference(['G','NIR']).rename('NDWI').float());
}

 function calcNDII(img){
  return img.addBands(img.normalizedDifference(['NIR','SWIR1']).rename('NDII').float());
}

 function calcMSI(img){
  var MSI = img.expression(
    "SWIR1 / NIR", 
    {
    SWIR1: img.select('SWIR1'),
    NIR: img.select('NIR'),
    });
    return img
    .addBands(MSI.rename('MSI')).float();
}

 function calcEVI(img){
  var EVI = img.expression(
  '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', 
  {
    NIR: img.select('NIR'),
    RED: img.select('R'),
    BLUE: img.select('B'),
    });
    return img
    .addBands(EVI.rename('EVI')).float();
}

////////////////////////////////
/// apply scaling factor and rename bands ///////
////////////////////////////////

// Scaling data is needed to bring the data into the right format
// to actually represent the values
function applyScaleFactors(image) {
  // Select only the optical bands and divide by 10000
  var opticalBands = image.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12']).divide(10000);
  // Add the scaled optical bands back to the image
  image = image.addBands(opticalBands, null, true);
  return image;
}

// Define functions to select and rename bands for S2
function renameBands(image) {
    var bands = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12'];
    var new_bands = ['B', 'G', 'R', 'NIR', 'SWIR1', 'SWIR2'];
    return image.select(bands).rename(new_bands);
}

//////////////////////////////////
// load and filter the S2 data ///
//////////////////////////////////
var s2_col_20 = ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED")
            .filterBounds(dissolved)
            .map(function(image){return image.clip(dissolved)})
            .filter(ee.Filter.calendarRange(1,12,'month'))
            .filter(ee.Filter.calendarRange(2020,2020,'year'))
            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))
            .map(maskS2clouds)
            .map(applyScaleFactors)
            .map(renameBands)
            .map(calcNDVI)
            .map(calcNDWI)
           // .map(calcNDII)
            //.map(calcMSI)
           // .map(calcEVI);
print('S2 collection 20:', s2_col_20);
print('available S2 images 20:', s2_col_20.size());

// calculate the median composite
  var startDate = ee.Date.fromYMD(2020, 1, 1);
  var s2median20 = s2_col_20.median()
                .set('year', 2020)    
                .set('system:time_start', startDate.millis());

// Visualization parameters
var visParams = {
  bands: ['R', 'G', 'B'],
  min: 0,
  max: 0.3, 
  gamma: 1.4
};

Map.addLayer(s2median20, visParams, 's2median20', 0, 1)
print(s2median20, 's2median20')


///// for 2023 /////////

var s2_col_23 = ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED")
            .filterBounds(dissolved)
            .map(function(image){return image.clip(dissolved)})
            .filter(ee.Filter.calendarRange(1,12,'month'))
            .filter(ee.Filter.calendarRange(2023,2023,'year'))
            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))
            .map(maskS2clouds)
            .map(applyScaleFactors)
            .map(renameBands)
            .map(calcNDVI)
            .map(calcNDWI)
            //.map(calcNDII)
            //.map(calcMSI)
           // .map(calcEVI);
print('S2 collection 2023:', s2_col_23);
print('available S2 images 2023:', s2_col_23.size());


// calculate the median composite
  var startDate23 = ee.Date.fromYMD(2023, 1, 1);
  var s2median23 = s2_col_23.median()
                .set('year', 2023)    
                .set('system:time_start', startDate.millis());

Map.addLayer(s2median23, visParams, 's2median23', 0, 1);
print(s2median23, 's2median23')
print(s2median23.bandNames());

///////////////////////////////////////
//////////Overlay training points and split into traind and val///////////
///////////////////////////////////////

//// for 2020

// Overlay the point on the multi-temporal stack to include the band information in the feature collection.
var sample20 = s2median20.sampleRegions({
  collection: sample_sichifulo_20, 
  properties: ['LC_Nr'], 
  scale: 90, // has to be downscaled for computation time reasons
  geometries: true // coordinates maintained
});

// Create a column in the feature collection that assignes each feature a random value between 0-1 and define a seed number for reproducibility
var sample20 = sample20.randomColumn("random",123);

// Every feature with a value of less than 0.66 (2/3) is collected as a training feature,
// The rest is collected as validation features (1/3)
var split = 0.66;
var training20 = sample20.filter(ee.Filter.lt("random",split));
var validation20 = sample20.filter(ee.Filter.gte("random",split));

//print('training features 2020:', training20);
//print('samples 2020:', sample20);

////// and for 2023 ///////

// Overlay the point on the multi-temporal stack to include the band information in the feature collection.
var sample23 = s2median23.sampleRegions({
  collection: sample_sichifulo_23, 
  properties: ['LC_Nr'], 
  scale: 90,
  geometries : true // coordinates maintained
});

// Create a column in the feature collection that assignes each feature a random value between 0-1 and define a seed number for reproducibility
var sample23 = sample23.randomColumn("random",123);

// Every feature with a value of less than 0.66 (2/3) is collected as a training feature,
// The rest is collected as validation features (1/3)var split = 0.66;
var training23 = sample23.filter(ee.Filter.lt("random",split));
var validation23 = sample23.filter(ee.Filter.gte("random",split));

//print('training features 2023:', training23);
//print('samples 2023:', sample23);


//////////////////////////////////////
//classification function/////////////
//////////////////////////////////////#
 var RFclassification = function(train, img, area, val, name) {

  // Train the classifier using the training features
  var classifier = ee.Classifier.smileRandomForest(50).train({
    features: train,  
    classProperty: 'LC_Nr', 
    inputProperties: img.bandNames()
  });

  // Classify the multi-temporal stack
  var classification = img.classify(classifier);

  // Apply majority filter to filter out single pixels that have no adjacent pixels of the same class
  // those pixels are usually falsely classified
  var classificationFiltered = classification.focal_mode(1, "square");

  // Clip the classification to the ROI (it won't be clipped otherwise, even though the input is clipped)
  classificationFiltered = classificationFiltered.clip(area);
  
  // Classify validation points
  var validated = val.classify(classifier);
  
  // Compare reference and predicted classes
  var testAccuracy = validated.errorMatrix('LC_Nr', 'classification');

  // Return the classified scenes, their corresponding accuracies and the respective names
  return {classification: classificationFiltered, testAccuracy: testAccuracy, name: name, classifier: classifier};
};

////////////////// Define the different sets of inputs to iterate over and name the sets //////////////////////
var imgset = [
  {train: training20,
    img: s2median20, 
    area: dissolved,
    val: validation20,
    name: '2020'},
  {train: training23,
    img: s2median23, 
    area: dissolved,
    val: validation23,
    name: '2023'},
];

/////////////// Iterate over the image sets to apply the RF classification //////////////////
// also include accuracy assessment

for (var i = 0; i < imgset.length; i++) {
  var set = imgset[i];
  
  // Train, classify, and compute accuracy using the current set of bands
  var result = RFclassification(set.train, set.img, set.area, set.val, set.name);
  
  // Palette with the colors
var palette =['#0080FF', '#E5AA70', '#696969', '#FFCC33', '#7FFF00', '#808000', 'darkgreen', "#87CEEB"];  
  // Define visualization parameters
var visParams = {
  min: 1,
  max: 8,  // Assuming you have 7 classes (0 to 6)
  palette: palette
};

  // Add the classified layer to the map
  Map.addLayer(result.classification, visParams, 'Classification ' + result.name, 0, 1);
  
  // Print error matrix and overall accuracy of the classification for the respective set of bands
  print('Validation error matrix for ' + result.name + ': ', result.testAccuracy);
  print('Validation overall accuracy for ' + result.name + ': ', result.testAccuracy.accuracy());
}
  
  
///////////////////////////////////////////////////////////////
///////////// Adding a legend to the classified image /////////
///////////////////////////////////////////////////////////////  
  
// The code is copied and only slightly adjusted (change of classes and their colors) from the "classification lecture" slides

var legend = ui.Panel({ 
  style: { 
    position: 'bottom-left', 
    padding: '18px 25px'}}
    );

// Create legend title
var legendTitle = ui.Label({ 
  value: 'LCLU classification - Kaza region', 
  style: { 
    fontWeight: 'bold', 
    fontSize: '22px', 
    margin: '0 0 15px 0', 
    padding: ' 0 '}}
    );

// Add the title to the panel
legend.add(legendTitle);
// Creates and styles 1 row of the legend.
var makeRow = function(color, name) { 
  // Create the label that is actually the colored box. 
  var colorBox = ui.Label({ 
    style: { 
      backgroundColor: color, 
      // Use padding to give the box height and width. 
      padding: '10px', 
      margin: '0 0 5px 0'}
      }); 
    // Create the label filled with the description text. 
    var description = ui.Label({ 
      value: name, 
      style: {margin: '0 0 4px 16px',}
    });
    // return the panel 
    return ui.Panel({ 
      widgets: [colorBox, description], 
      layout: ui.Panel.Layout.Flow('horizontal')
    });
};
// Palette with the colors
var palette =['#0080FF', '#E5AA70', '#696969', '#FFCC33', '#7FFF00', '#808000', 'darkgreen', "#87CEEB"];
// Name of the legend
var names = ['Water', 'Bare', 'Built', 'Cropland', 'Grass', 'Shrub', 'Forest', 'Wetland'];
// Add color and and names
for (var i = 0; i < 8; i++) { 
  legend.add(makeRow(palette[i], names[i]));
}
// Add legend to map (alternatively you can also print the legend to the console)
Map.add(legend);
var legend = ui.Panel({ 
  style: { 
    position: 'bottom-left', 
    padding: '18px 25px'}
});


/////////////////////////////////////////////////////////////////////////////
/////////calculate the respective area of the classes in sqkm ///////////////
/////////////////////////////////////////////////////////////////////////////

// Iterate over band sets
for (var i = 0; i < imgset.length; i++) {
  
  var set = imgset[i];
  
  // the classification has to be conducted again in this function to retrieve results
  var result = RFclassification(set.train, set.img, set.area, set.val, set.name);

// Define a scale for the calculation (30 meters)
var scale = 90;

// Define a dictionary of class names and their corresponding values in the classified image
var classNames = {
  'Water': 1,
  'Bare': 2,
  'Built': 3,
  'Cropland': 4,
  'Grass': 5,
  'Shrub': 6,
  'Forest': 7,
  'Wetland': 8
};

// Create an empty list to store the area per class
var areaList = [];

// Iterate over the class names
for (var Name in classNames) {
  // Filter the classified image for the current class
  var classImage = result.classification.eq(classNames[Name]);
  
  // Compute the area for the current class
  var area = classImage.multiply(ee.Image.pixelArea()).rename('area');
  
  // Reduce the region to compute the total area in square meters
  var classArea = area.reduceRegion({
    reducer: ee.Reducer.sum(),
    geometry: dissolved,
    scale: scale,
    maxPixels: 1e13 
  });
  
  // Get the total area in square kilometers
  var areaSqkm = ee.Number(classArea.get('area')).divide(1e6); 
  
  // Add the class name and area value to the list
  areaList.push([Name, areaSqkm]);
}

// Print the area per class for the classifications with different sets of bands
print('Area per class for ' + result.name + ' in sqkm: ', areaList);

}



////////////////////////////////////////////////////////////////7
///////// change detection ////////////////////////////////////////
///////////////////////////////////////////////////////////////

// Step 3: Define the land cover class of interest (e.g., Forest class = 1)
var landCoverClass = 4;


// Iterate over band sets

  var set20 = imgset[0];
  var set23 = imgset[1];
  
  // the classification has to be conducted again in this function to retrieve results
  var result20 = RFclassification(set20.train, set20.img, set20.area, set20.val, set20.name);
  var result23 = RFclassification(set23.train, set23.img, set23.area, set23.val, set23.name);


// Step 4: Extract the specific land cover class
var classYear1 = result20.classification.eq(landCoverClass);
var classYear2 = result23.classification.eq(landCoverClass);

// Step 5: Compute the change detection map
var changeDetection = classYear2.subtract(classYear1);

// Step 6: Define visualization parameters
var visParams = {
  min: -1,
  max: 1,
  palette: ['red', 'white', 'green']
};

// Step 7: Visualize the results
Map.addLayer(changeDetection, visParams, 'Change Detection');

// Optional: Export the change detection map
Export.image.toDrive({
  image: changeDetection,
  description: 'ChangeDetection',
  scale: 90,
  region: dissolved,
  maxPixels: 1e13
});
