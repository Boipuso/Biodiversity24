// Load your uploaded asset as an EE object
var dissolved = ee.FeatureCollection("users/Henning/Biodiversity/sichifulo_zam_Dissolve_Chooma_Nyawa");
var sample_sichifulo_23 = ee.FeatureCollection("users/Henning/Biodiversity/agri_sample23");
var sample_sichifulo_20 = ee.FeatureCollection("users/Henning/Biodiversity/agri_sample20");

//print('Dissolve_Chooma_Nyawa:', Dissolve_Chooma_Nyawa);
print('sample_sichifulo_20:', sample_sichifulo_20);

// Add the asset to the map with visualization parameters
Map.addLayer(dissolved, {color: 'green'}, 'dissolved');
Map.addLayer(sample_sichifulo_20, {color: 'orange'}, 'sample_sichifulo_20');

// Center the map on the asset
Map.centerObject(dissolved, 10);


////////////////////////////////////////////////////////
////////////cloud masking/////////////////////////////7
////////////////////////////////////////////////////////
// Function to remove cloud and snow pixels
function maskS2clouds(image) {
  var cloudProb = image.select('MSK_CLDPRB');
  var snowProb = image.select('MSK_SNWPRB');
  var cloud = cloudProb.lt(5);
  var snow = snowProb.lt(5);
  var scl = image.select('SCL'); 
  var shadow = scl.eq(3); // 3 = cloud shadow
  var cirrus = scl.eq(10); // 10 = cirrus
  // Cloud probability less than 5% or cloud shadow classification
  var mask = (cloud.and(snow)).and(cirrus.neq(1)).and(shadow.neq(1));
 return image.updateMask(mask);
}

/////////////////////////////////////////////////7
//////////Indices calculation////////////////////
//////////////////////////////////////////////////

// Indices: 
// NDVI = (NIR-RED) / (NIR+RED)
// NDWI = (GREEN-NIR) / (GREEN+NIR)

function calcNDVI(img){
  return img.addBands(img.normalizedDifference(['NIR','R']).rename('NDVI').float());
}
 
 function calcNDWI(img){
  return img.addBands(img.normalizedDifference(['G','NIR']).rename('NDWI').float());
}

////////////////////////////////
/// apply scaling factor and rename bands ///////
////////////////////////////////

// Scaling data is needed to bring the data into the right format
// to actually represent the values
function applyScaleFactors(image) {
  // Select only the optical bands and divide by 10000
  var opticalBands = image.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12']).divide(10000);
  // Add the scaled optical bands back to the image
  image = image.addBands(opticalBands, null, true);
  return image;
}

// Define functions to select and rename bands for S2
function renameBands(image) {
    var bands = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12'];
    var new_bands = ['B', 'G', 'R', 'NIR', 'SWIR1', 'SWIR2'];
    return image.select(bands).rename(new_bands);
}

//////////////////////////////////
// load and filter the S2 data ///
//////////////////////////////////
var s2_col_20 = ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED")
            .filterBounds(dissolved)
            .map(function(image){return image.clip(dissolved)})
            .filter(ee.Filter.calendarRange(1,12,'month'))
            .filter(ee.Filter.calendarRange(2020,2020,'year'))
            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))
            .map(maskS2clouds)
            .map(applyScaleFactors)
            .map(renameBands)
            .map(calcNDVI)
            .map(calcNDWI);
print('S2 collection 20:', s2_col_20);
print('available S2 images 20:', s2_col_20.size());


// calculate the median composite
  var startDate = ee.Date.fromYMD(2020, 1, 1);
  var s2median20 = s2_col_20.median()
                .set('year', 2020)    
                .set('system:time_start', startDate.millis());
                
// Visualization parameters
var visParams = {
  bands: ['R', 'G', 'B'],
  min: 0,
  max: 0.3, 
  gamma: 1.4
};

Map.addLayer(s2median20, visParams, 's2median20', 0, 1)
print(s2median20, 's2median20')



////////////////////////////////////////////////////////////
////NICS segmentation////////////////
////////////////////////

// prepare snic
// Prepare SNIC
var kernel = ee.Kernel.gaussian(3);
s2median20 = s2median20.convolve(kernel);

var seeds = ee.Algorithms.Image.Segmentation.seedGrid(10, 'hex');


// Apply SNIC segmentation
var snic20 = ee.Algorithms.Image.Segmentation.SNIC({
  image: s2median20,
  size: 10,
  compactness: 0,
  connectivity: 8,
  neighborhoodSize: 128,
  seeds: seeds
}).reproject({
  crs: 'EPSG:4326',
  scale: 30
});

print(snic20, "snic20")


// Extract clusters and their properties
var clusters20 = snic20.select('clusters');
var segmentedImage20 = snic20.select([".*_mean$"]); // Adjust band names as needed
print("segmentedImage 2020", segmentedImage20)

// Visualize clusters
//Map.addLayer(clusters.randomVisualizer(), {}, 'Clusters');


///////////////////////////////////////
//////////Overlay training points and split into train and val///////////
///////////////////////////////////////

//// for 2020

// Overlay the point on the multi-temporal stack to include the band information in the feature collection.
var sample20 = segmentedImage20.sampleRegions({
  collection: sample_sichifulo_20, 
  properties: ['LC_Nr'], 
  scale: 30,
  geometries: true // coordinates maintained
});

// Create a column in the feature collection that assignes each feature a random value between 0-1 and define a seed number for reproducibility
var sample20 = sample20.randomColumn("random",123);

// Every feature with a value of less than 0.66 (2/3) is collected as a training feature,
// The rest is collected as validation features (1/3)
var split = 0.7;
var training20 = sample20.filter(ee.Filter.lt("random",split));
var validation20 = sample20.filter(ee.Filter.gte("random",split));

//print('training features 2020:', training20);
//print('samples 2020:', sample20);


//////////////////////////////////////
//classification function/////////////
//////////////////////////////////////#
 var RFclassification = function(train, img, area, val, name) {

  // Train the classifier using the training features
  var classifier = ee.Classifier.smileRandomForest(50).train({
    features: train,  
    classProperty: 'LC_Nr', 
    inputProperties: img.bandNames()
  });

  // Classify the multi-temporal stack
  var classification = img.classify(classifier);

  // Apply majority filter to filter out single pixels that have no adjacent pixels of the same class
  // those pixels are usually falsely classified
  var classificationFiltered = classification.focal_mode(1, "square");

  // Clip the classification to the ROI (it won't be clipped otherwise, even though the input is clipped)
  classificationFiltered = classificationFiltered.clip(area);
  
  // Classify validation points
  var validated = val.classify(classifier);
  
  // Compare reference and predicted classes
  var testAccuracy = validated.errorMatrix('LC_Nr', 'classification');

  // Return the classified scenes, their corresponding accuracies and the respective names
  return {classification: classificationFiltered, testAccuracy: testAccuracy, name: name, classifier: classifier};
};



/////////////// Iterate over the image sets to apply the RF classification //////////////////
// also include accuracy assessment

  // Train, classify, and compute accuracy using the current set of bands
  var result = RFclassification(training20, segmentedImage20, dissolved, validation20, '2020');
  
  // Palette with the colors
  var palette =['black', '#FFCC33'];

  // Define visualization parameters
var visParams = {
  min: 0,
  max: 1,  // Assuming you have 7 classes (0 to 6)
  palette: palette
};

  // Add the classified layer to the map
  Map.addLayer(result.classification, visParams, 'Classification ' + result.name);
  
  // Print error matrix and overall accuracy of the classification for the respective set of bands
  print('Validation error matrix for ' + result.name + ': ', result.testAccuracy);
  print('Validation overall accuracy for ' + result.name + ': ', result.testAccuracy.accuracy());
